{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efaad6bf",
   "metadata": {},
   "source": [
    "# Generating the synthetic stations and their apparatus assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "assignment_cols = ['StationID', 'Engine', 'Truck', 'Rescue', 'Hazard', 'Squad', 'FAST', 'Medic', 'Brush', 'Boat', 'UTV', 'REACH']\n",
    "station_cols = ['StationID', 'Facility Name', 'Address', 'City', 'State', 'Zip Code', 'GLOBALID', 'lat', 'lon']\n",
    "sdf = pd.read_csv(\"/Users/jose/Developer/git/fire_simulator/data/stations.csv\")\n",
    "sdf.loc[sdf['Facility Name'] == 'Station 41 / Goodlettesville', 'Facility Name'] = 'Station 41'\n",
    "sdf['StationID'] = sdf['Facility Name'].str.split(' ').str[1]\n",
    "sdf = sdf[station_cols]\n",
    "sdf['StationID'] = sdf['StationID'].astype('int')\n",
    "sdf = sdf.sort_values(by='StationID')\n",
    "sdf = sdf.reset_index(drop=True)\n",
    "sdf['StationID'] = sdf.index\n",
    "sdf.head()\n",
    "assignments = []\n",
    "for k, v in sdf.iterrows():\n",
    "    values = [v['StationID']] + [2] + [0] * (len(assignment_cols) - 2)\n",
    "    assignments.append(values)\n",
    "adf = pd.DataFrame(assignments, columns=assignment_cols)\n",
    "adf.to_csv(\"./data/assignments.csv\", index=False)\n",
    "sdf.to_csv(\"./data/stations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ee575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "# Get actual bounds of the city.\n",
    "df = gpd.read_file(\"data/bounds.geojson\")\n",
    "df.plot()\n",
    "df.minimum_rotated_rectangle().to_file(\"data/bounds_mrr.geojson\", driver=\"GeoJSON\")\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "stations = pd.read_csv(\"data/stations.csv\")\n",
    "incidents = pd.read_csv(\"data/incidents.csv\")\n",
    "# plot the two dataframes on a map\n",
    "stations_gdf = gpd.GeoDataFrame(\n",
    "    stations, geometry=gpd.points_from_xy(stations.lon, stations.lat), crs=\"EPSG:4326\"\n",
    ")\n",
    "incidents_gdf = gpd.GeoDataFrame(\n",
    "    incidents, geometry=gpd.points_from_xy(incidents.lon, incidents.lat), crs=\"EPSG:4326\"\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "stations_gdf.plot(ax=ax, color='blue', markersize=5, label='Stations')\n",
    "incidents_gdf.plot(ax=ax, color='red', markersize=5, label='Incidents')\n",
    "# add the station and incident labels\n",
    "for x, y, label in zip(stations_gdf.geometry.x, stations_gdf.geometry.y, stations_gdf['StationID']):\n",
    "    ax.text(x, y, label, fontsize=8, ha='right', va='bottom', color='blue')\n",
    "for x, y, label in zip(incidents_gdf.geometry.x, incidents_gdf.geometry.y, incidents_gdf['incident_id']):\n",
    "    ax.text(x, y, label, fontsize=8, ha='right', va='bottom', color='red')\n",
    "plt.legend()\n",
    "plt.title('Fire Stations and Incidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c94584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "date_range = pd.date_range(start=\"2022-01-01\", end=\"2022-12-31\", freq='1D')\n",
    "# 325002//len(date_range), len(date_range)\n",
    "PER_DAY = 314\n",
    "COUNT = PER_DAY * len(date_range)\n",
    "COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f0438",
   "metadata": {},
   "source": [
    "# Generating synthetic incident data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "import requests\n",
    "from pandas import to_datetime, Timedelta\n",
    "\n",
    "def generate_random_points_within_bounds(bounds, num_points):\n",
    "    minx, miny, maxx, maxy = bounds.bounds\n",
    "    points = []\n",
    "    for _ in range(num_points):\n",
    "        epsilon = 1e-8  # A very small value\n",
    "        x = random.uniform(minx + epsilon, maxx - epsilon)\n",
    "        y = random.uniform(miny + epsilon, maxy - epsilon)\n",
    "        points.append(Point(x, y))\n",
    "    return points\n",
    "\n",
    "def get_nearest_lat_lon(point, osrm_url):\n",
    "    response = requests.get(f\"{osrm_url}/nearest/v1/driving/{point.x},{point.y}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data['waypoints']:\n",
    "            return data['waypoints'][0]['location']\n",
    "    return None\n",
    "\n",
    "def generate_incidents(num_incidents, incident_types, incident_levels, date_range, nearest_points):\n",
    "    incidents = []\n",
    "    for idx in range(num_incidents):\n",
    "        incident_type = random.choice(incident_types)\n",
    "        incident_level = random.choice(incident_levels)\n",
    "        date_time = random.choice(date_range)\n",
    "        lon, lat = random.choice(nearest_points)\n",
    "        incidents.append({\n",
    "            \"incident_id\": f\"{idx}\",\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon,\n",
    "            \"incident_type\": incident_type,\n",
    "            \"incident_level\": incident_level,\n",
    "            \"datetime\": date_time,\n",
    "        })\n",
    "    return pd.DataFrame(incidents)\n",
    "\n",
    "osrm_url = \"http://localhost:8085\"\n",
    "num_incidents = 400\n",
    "nearest_points = []\n",
    "\n",
    "# Get actual bounds of the city.\n",
    "df = gpd.read_file(\"data/bounds.geojson\")\n",
    "# Generate random points within the bounds.\n",
    "random_points = generate_random_points_within_bounds(df.unary_union, num_incidents)\n",
    "# for each point, query the nearest lat lon on the street network with osrm\n",
    "for point in random_points:\n",
    "    nearest = get_nearest_lat_lon(point, osrm_url)\n",
    "    if nearest:\n",
    "        nearest_points.append(nearest)\n",
    "\n",
    "incident_types = [\"Fire\"]\n",
    "incident_levels = [\"Low\", \"Moderate\", \"High\", \"Critical\"]\n",
    "# date_range = pd.date_range(start=\"2022-01-01\", end=\"2024-10-29\", freq='1T')\n",
    "date_range = pd.date_range(start=\"2022-01-01\", end=\"2022-01-02\", freq='5T')\n",
    "\n",
    "incidents_df = generate_incidents(num_incidents, incident_types, incident_levels, date_range, nearest_points)\n",
    "incidents_df = incidents_df.sort_values(by='datetime')\n",
    "incidents_df = incidents_df.reset_index(drop=True)\n",
    "incidents_df['incident_id'] = incidents_df.index\n",
    "\n",
    "\n",
    "# Ensure datetime is in datetime format and sorted\n",
    "\n",
    "seen = set()\n",
    "for idx, row in incidents_df.iterrows():\n",
    "    dt = row['datetime']\n",
    "    # Increment by 1 minute until unique\n",
    "    while dt in seen:\n",
    "        dt += Timedelta(minutes=1)\n",
    "    incidents_df.at[idx, 'datetime'] = dt\n",
    "    seen.add(dt)\n",
    "\n",
    "incidents_df['datetime'] = pd.to_datetime(incidents_df['datetime'])\n",
    "incidents_df = incidents_df.sort_values('datetime').reset_index(drop=True)\n",
    "incidents_df.to_csv(\"data/incidents.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f4bf7",
   "metadata": {},
   "source": [
    "# Plotting the differences between different OSRM instances\n",
    "* One is turning off wrong way driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f3abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given this url: http://localhost:8080/route/v1/driving/-86.7816,36.1627;-86.7679,36.1745?overview=full&geometries=geojson\n",
    "# plot the route on the map.\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "from shapely.geometry import shape\n",
    "\n",
    "def plot_route(osrm_url, start, end):\n",
    "    response = requests.get(f\"{osrm_url}/route/v1/driving/{start[0]},{start[1]};{end[0]},{end[1]}?overview=full&geometries=geojson\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data['routes']:\n",
    "            route_geojson = data['routes'][0]['geometry']\n",
    "            route_shape = shape(route_geojson)\n",
    "            route_gdf = gpd.GeoDataFrame(geometry=[route_shape], crs=\"EPSG:4326\")\n",
    "            return route_gdf\n",
    "    return None\n",
    "\n",
    "# Normal car version\n",
    "osrm_url = \"http://localhost:8080\"\n",
    "\n",
    "start = (-86.7816, 36.1627)\n",
    "end = (-86.7679, 36.1745)\n",
    "\n",
    "route_gdf = plot_route(osrm_url, start, end)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "if route_gdf is not None:\n",
    "    route_gdf.plot(ax=ax, color='blue', linewidth=5, label='CAR')\n",
    "\n",
    "# EMS version\n",
    "osrm_url = \"http://localhost:8085\"\n",
    "\n",
    "start = (-86.7816, 36.1627)\n",
    "end = (-86.7679, 36.1745)\n",
    "\n",
    "route_gdf = plot_route(osrm_url, start, end)\n",
    "\n",
    "if route_gdf is not None:\n",
    "    route_gdf.plot(ax=ax, color='red', linewidth=2, label='EMS')\n",
    "    ax.set_title(\"Route from Start to End\")\n",
    "\n",
    "ctx.add_basemap(ax, crs=route_gdf.crs.to_string())\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c896bd7",
   "metadata": {},
   "source": [
    "# Cleaning and Preparing the Zones geojson\n",
    "* Split multipolygons into separate polygons, but keep the names and zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cddb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import re\n",
    "\n",
    "def split_string(s):\n",
    "    match = re.match(r'^(\\d+)(.*)$', s)\n",
    "    if match:\n",
    "        number = int(match.group(1))\n",
    "        suffix = match.group(2) if match.group(2) else None\n",
    "        return number, suffix\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid input: {s}\")\n",
    "\n",
    "# Suppose 'union_polygon' may be a MultiPolygon or Polygon\n",
    "def split_to_polygons(geom):\n",
    "    if geom.geom_type == 'MultiPolygon':\n",
    "        return list(geom.geoms)\n",
    "    elif geom.geom_type == 'Polygon':\n",
    "        return [geom]\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "df = gpd.read_file(\"data/FireBeats_shapefile_05152025\")\n",
    "# Convert to 4326\n",
    "df = df.to_crs(epsg=4326)\n",
    "df_arr = []\n",
    "for k, v in df.groupby(\"NAME\"):\n",
    "    union_polygon = v.union_all()\n",
    "    # split the name into int and string components\n",
    "\n",
    "    i_name, s_name = split_string(k)\n",
    "    if s_name is not None:\n",
    "        name = f\"{str(i_name).zfill(2)}{s_name}\"\n",
    "    else:\n",
    "        name = str(i_name).zfill(2)\n",
    "    polygons = split_to_polygons(union_polygon)\n",
    "    for poly in polygons:\n",
    "        data = {\n",
    "            \"NAME\": name,\n",
    "            \"ZONE\": v[\"ZONE\"].iloc[0],\n",
    "            \"TYPE\": v[\"TYPE\"].iloc[0],\n",
    "            \"geometry\": poly\n",
    "        }\n",
    "        df_arr.append(data)\n",
    "df = gpd.GeoDataFrame(df_arr, crs=\"EPSG:4326\")\n",
    "df.to_file(\"data/beats_shpfile.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f3850",
   "metadata": {},
   "source": [
    "# Setting up the beats matrix\n",
    "* Requires the FIRE RUN CARDS OCT 2024 folder to be present.\n",
    "* Fire run cards directory should have files named:\n",
    "    * Beat-ZONE.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839098fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbe9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file(\"data/FireBeats_shapefile_05152025\")\n",
    "zones = df['NAME'].unique()\n",
    "zones = sorted(zones)\n",
    "zones[1:5]\n",
    "\n",
    "# What are these names and what do they correspond to?\n",
    "ignored_names = [\n",
    "    \"FD/RADIO\",\n",
    "    \"FD/FST11\",\n",
    "    \"FD/FST06\",\n",
    "    \"FD/FST09\",\n",
    "    \"FD/FST37\",\n",
    "    \"FD/FAST01\",\n",
    "    \"FD/SQ01\",\n",
    "    \"FD/SQ37\",\n",
    "    \"FD/SQ09\",\n",
    "    \"FD/SQ11\",\n",
    "    \"FD/TC05\",\n",
    "    \"FD/DS31\",\n",
    "    \"FD/MED41\",\n",
    "    \"FD/HQ\",\n",
    "    \"FD/BAR*\",\n",
    "    \"FD/DSOP\",\n",
    "    \"FD/BT13\", \"FD/BT22\", \"FD/BT35\", \"FD/BT36\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03e1823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/FIRE RUN CARDS OCT 2024/BEAT-10.xlsx does not exist. Skipping.\n",
      "File data/FIRE RUN CARDS OCT 2024/BEAT-15A.xlsx does not exist. Skipping.\n",
      "File data/FIRE RUN CARDS OCT 2024/BEAT-07R.xlsx does not exist. Skipping.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Read the Excel file and specify the sheet name (or use sheet number)\n",
    "excel_path = \"data/FIRE RUN CARDS OCT 2024/\"\n",
    "sheet_name = \"RunCardOrder\"  # Change to your actual sheet name\n",
    "\n",
    "beats = []\n",
    "max_runs = 0\n",
    "for zone_name in zones:\n",
    "\n",
    "    i_name, s_name = split_string(zone_name)\n",
    "    # print(i_name, s_name)\n",
    "    if s_name is not None:\n",
    "        new_name = f\"{str(i_name).zfill(2)}{s_name}\"\n",
    "    else:\n",
    "        new_name = str(i_name).zfill(2)\n",
    "    # Construct the full path to the Excel file for the specific zone\n",
    "    excel_path = f\"data/FIRE RUN CARDS OCT 2024/BEAT-{new_name}.xlsx\"\n",
    "    \n",
    "    # Check if the file exists before proceeding\n",
    "    if not os.path.exists(excel_path):\n",
    "        print(f\"File {excel_path} does not exist. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Read the sheet into a DataFrame\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "    # Confirm these with Fire Department\n",
    "    df = df[~df['OrderValue'].isin(ignored_names)]\n",
    "    df = df[~df['OrderValue'].str.contains(\"FST\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"FB\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"SQ\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"MED\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"BT\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"DSOP\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"RADIO\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"HQ\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"EN\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"RE\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"ATV\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"TC\")]\n",
    "    df = df[~df['OrderValue'].str.contains(\"BAR\")]\n",
    "    df['Facility Name'] = df['OrderValue'].str.split('/').str[1]\n",
    "    try:\n",
    "        df['Facility Name'] = df['Facility Name'].str.replace('S', 'Station ')\n",
    "        df['StationID'] = df['Facility Name'].str.split(' ').str[1]\n",
    "        df['StationID'] = df['StationID'].astype('int')\n",
    "        df['Facility Name'] = 'Station ' + df['StationID'].astype(str).str.zfill(2)\n",
    "        df.drop(columns=['StationID'], inplace=True)\n",
    "    except Exception as e:\n",
    "        print(new_name, e)\n",
    "        # display(df.head())\n",
    "\n",
    "    max_runs = max(max_runs, df['OrderValue'].shape[0])\n",
    "    run_order = df['Facility Name'].tolist()\n",
    "    if len(run_order) < max_runs:\n",
    "        run_order += [\"None\"] * (max_runs - len(run_order))\n",
    "    run_order = [new_name] + run_order\n",
    "    beats.append(run_order)\n",
    "df = pd.DataFrame(beats, columns=['Zone'] + [f'Run {i+1}' for i in range(max_runs)])\n",
    "# replace all '' in df with 'None'\n",
    "df = df.replace('', 'None')\n",
    "df = df.fillna('None')\n",
    "for i in range(len(beats)):\n",
    "    # print(beats[i])\n",
    "    if len(beats[i]) < max_runs:\n",
    "        beats[i] += [\"None\"] * (max_runs - len(beats[i]))\n",
    "    # print(len(beats[i]))\n",
    "df.to_csv(\"data/beats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9aded38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def save_string_matrix(filename, matrix):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        height = len(matrix)\n",
    "        width = len(matrix[0]) if height > 0 else 0\n",
    "        f.write(struct.pack(\"ii\", width, height))\n",
    "\n",
    "        for row in matrix:\n",
    "            for s in row:\n",
    "                s_bytes = s.encode(\"utf-8\")\n",
    "                f.write(struct.pack(\"i\", len(s_bytes)))\n",
    "                f.write(s_bytes)\n",
    "matrix = df.to_numpy().tolist()\n",
    "save_string_matrix(\"logs/beats.bin\", matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de43c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(beats[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e7556bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '10A', '10B', '10C', '10D', '10E', '10F', '11', '11B', '11C',\n",
       "       '11D', '11E', '11F', '11G', '11H', '11R1', '11R2', '12', '12B',\n",
       "       '12C', '12D', '12E', '12F', '12G', '12H', '12R', '13', '13B',\n",
       "       '13C', '13D', '13E', '13F', '13G', '13H', '13I', '13J', '13K',\n",
       "       '13R1', '13R2', '14', '14B', '14C', '14D', '14E', '14R1', '14R2',\n",
       "       '15', '15B', '15C', '15D', '15E', '15F', '16', '16B', '16C', '16D',\n",
       "       '16E', '16F', '16G', '16H', '17', '17A', '17B', '17C', '17D',\n",
       "       '17E', '17F', '18', '18B', '18C', '18D', '18E', '18F', '18G',\n",
       "       '18H', '18I', '18R', '19', '19B', '19C', '19D', '19E', '19F',\n",
       "       '19G', '19H', '19I', '19J', '02', '20', '20B', '20C', '20D', '20E',\n",
       "       '20F', '20G', '20H', '20K', '20L', '20M', '21', '21B', '21C',\n",
       "       '21D', '21E', '21F', '21G', '21I', '21J', '21K', '22', '22B',\n",
       "       '22C', '22D', '22R1', '22R2', '23', '23B', '23C', '23R1', '23R2',\n",
       "       '24', '24B', '24C', '24D', '24E', '24F', '24R1', '24R2', '24R3',\n",
       "       '25', '25A', '25B', '25C', '25D', '25R', '26', '26B', '26C', '26D',\n",
       "       '27', '27A', '27B', '27C', '27D', '27E', '27F', '27L', '28', '28B',\n",
       "       '28C', '28D', '28E', '28F', '28G', '28H', '28L1', '28L2', '28L3',\n",
       "       '28L4', '28L5', '28R', '29', '29B', '29C', '29D', '29E', '29F',\n",
       "       '29R', '03', '30', '30B', '30F', '30L', '31', '31B', '31C', '31D',\n",
       "       '31E', '31H', '31I', '31J', '31K', '31M', '31N', '31O', '31P',\n",
       "       '31R1', '31R2', '32', '32E', '32F', '32G', '32H', '32I', '33',\n",
       "       '33B', '33C', '33D', '33E', '34', '34B', '34C', '34R', '35', '35B',\n",
       "       '35C', '35CL', '35I', '35L1', '35L2', '35L3', '35L4', '35L5',\n",
       "       '35L6', '36', '36C', '36L1', '36L2', '36R1', '36R2', '37', '37B',\n",
       "       '37C', '37D', '37E', '37G', '38B', '38E', '38H', '38R1', '38R2',\n",
       "       '38R3', '38R4', '39C', '39D', '39E', '39G', '39H', '39I', '39J',\n",
       "       '39K', '39M', '04', '40', '40A', '40Ap', '40B', '40Bp', '40C',\n",
       "       '40D', '40L1', '40R1', '40R2', '40R3', '41', '41B', '41C', '41D',\n",
       "       '41E', '41F', '41G', '41R', '06', '07', '7R', '08', '09'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Zone.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "396416ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '10',\n",
       " '10A',\n",
       " '10B',\n",
       " '10C',\n",
       " '10D',\n",
       " '10E',\n",
       " '10F',\n",
       " '11',\n",
       " '11B',\n",
       " '11C',\n",
       " '11D',\n",
       " '11E',\n",
       " '11F',\n",
       " '11G',\n",
       " '11H',\n",
       " '11R1',\n",
       " '11R2',\n",
       " '12',\n",
       " '12B',\n",
       " '12C',\n",
       " '12D',\n",
       " '12E',\n",
       " '12F',\n",
       " '12G',\n",
       " '12H',\n",
       " '12R',\n",
       " '13',\n",
       " '13B',\n",
       " '13C',\n",
       " '13D',\n",
       " '13E',\n",
       " '13F',\n",
       " '13G',\n",
       " '13H',\n",
       " '13I',\n",
       " '13J',\n",
       " '13K',\n",
       " '13R1',\n",
       " '13R2',\n",
       " '14',\n",
       " '14B',\n",
       " '14C',\n",
       " '14D',\n",
       " '14E',\n",
       " '14R1',\n",
       " '14R2',\n",
       " '15',\n",
       " '15A',\n",
       " '15B',\n",
       " '15C',\n",
       " '15D',\n",
       " '15E',\n",
       " '15F',\n",
       " '16',\n",
       " '16B',\n",
       " '16C',\n",
       " '16D',\n",
       " '16E',\n",
       " '16F',\n",
       " '16G',\n",
       " '16H',\n",
       " '17',\n",
       " '17A',\n",
       " '17B',\n",
       " '17C',\n",
       " '17D',\n",
       " '17E',\n",
       " '17F',\n",
       " '18',\n",
       " '18B',\n",
       " '18C',\n",
       " '18D',\n",
       " '18E',\n",
       " '18F',\n",
       " '18G',\n",
       " '18H',\n",
       " '18I',\n",
       " '18R',\n",
       " '19',\n",
       " '19B',\n",
       " '19C',\n",
       " '19D',\n",
       " '19E',\n",
       " '19F',\n",
       " '19G',\n",
       " '19H',\n",
       " '19I',\n",
       " '19J',\n",
       " '1B',\n",
       " '1C',\n",
       " '1D',\n",
       " '1E',\n",
       " '1F',\n",
       " '1G',\n",
       " '1H',\n",
       " '1I',\n",
       " '2',\n",
       " '20',\n",
       " '20B',\n",
       " '20C',\n",
       " '20D',\n",
       " '20E',\n",
       " '20F',\n",
       " '20G',\n",
       " '20H',\n",
       " '20K',\n",
       " '20L',\n",
       " '20M',\n",
       " '21',\n",
       " '21B',\n",
       " '21C',\n",
       " '21D',\n",
       " '21E',\n",
       " '21F',\n",
       " '21G',\n",
       " '21I',\n",
       " '21J',\n",
       " '21K',\n",
       " '22',\n",
       " '22B',\n",
       " '22C',\n",
       " '22D',\n",
       " '22R1',\n",
       " '22R2',\n",
       " '23',\n",
       " '23B',\n",
       " '23C',\n",
       " '23R1',\n",
       " '23R2',\n",
       " '24',\n",
       " '24B',\n",
       " '24C',\n",
       " '24D',\n",
       " '24E',\n",
       " '24F',\n",
       " '24R1',\n",
       " '24R2',\n",
       " '24R3',\n",
       " '25',\n",
       " '25A',\n",
       " '25B',\n",
       " '25C',\n",
       " '25D',\n",
       " '25R',\n",
       " '26',\n",
       " '26B',\n",
       " '26C',\n",
       " '26D',\n",
       " '27',\n",
       " '27A',\n",
       " '27B',\n",
       " '27C',\n",
       " '27D',\n",
       " '27E',\n",
       " '27F',\n",
       " '27L',\n",
       " '28',\n",
       " '28B',\n",
       " '28C',\n",
       " '28D',\n",
       " '28E',\n",
       " '28F',\n",
       " '28G',\n",
       " '28H',\n",
       " '28L1',\n",
       " '28L2',\n",
       " '28L3',\n",
       " '28L4',\n",
       " '28L5',\n",
       " '28R',\n",
       " '29',\n",
       " '29B',\n",
       " '29C',\n",
       " '29D',\n",
       " '29E',\n",
       " '29F',\n",
       " '29R',\n",
       " '2B',\n",
       " '2C',\n",
       " '2D',\n",
       " '2E',\n",
       " '2F',\n",
       " '2G',\n",
       " '2H',\n",
       " '2R',\n",
       " '3',\n",
       " '30',\n",
       " '30B',\n",
       " '30F',\n",
       " '30L',\n",
       " '31',\n",
       " '31B',\n",
       " '31C',\n",
       " '31D',\n",
       " '31E',\n",
       " '31H',\n",
       " '31I',\n",
       " '31J',\n",
       " '31K',\n",
       " '31M',\n",
       " '31N',\n",
       " '31O',\n",
       " '31P',\n",
       " '31R1',\n",
       " '31R2',\n",
       " '32',\n",
       " '32E',\n",
       " '32F',\n",
       " '32G',\n",
       " '32H',\n",
       " '32I',\n",
       " '33',\n",
       " '33B',\n",
       " '33C',\n",
       " '33D',\n",
       " '33E',\n",
       " '34',\n",
       " '34B',\n",
       " '34C',\n",
       " '34R',\n",
       " '35',\n",
       " '35B',\n",
       " '35C',\n",
       " '35CL',\n",
       " '35I',\n",
       " '35L1',\n",
       " '35L2',\n",
       " '35L3',\n",
       " '35L4',\n",
       " '35L5',\n",
       " '35L6',\n",
       " '36',\n",
       " '36C',\n",
       " '36L1',\n",
       " '36L2',\n",
       " '36R1',\n",
       " '36R2',\n",
       " '37',\n",
       " '37B',\n",
       " '37C',\n",
       " '37D',\n",
       " '37E',\n",
       " '37G',\n",
       " '38B',\n",
       " '38E',\n",
       " '38H',\n",
       " '38R1',\n",
       " '38R2',\n",
       " '38R3',\n",
       " '38R4',\n",
       " '39C',\n",
       " '39D',\n",
       " '39E',\n",
       " '39G',\n",
       " '39H',\n",
       " '39I',\n",
       " '39J',\n",
       " '39K',\n",
       " '39M',\n",
       " '3B',\n",
       " '3C',\n",
       " '3D',\n",
       " '3E',\n",
       " '3F',\n",
       " '3R',\n",
       " '4',\n",
       " '40',\n",
       " '40A',\n",
       " '40Ap',\n",
       " '40B',\n",
       " '40Bp',\n",
       " '40C',\n",
       " '40D',\n",
       " '40L1',\n",
       " '40R1',\n",
       " '40R2',\n",
       " '40R3',\n",
       " '41',\n",
       " '41B',\n",
       " '41C',\n",
       " '41D',\n",
       " '41E',\n",
       " '41F',\n",
       " '41G',\n",
       " '41R',\n",
       " '4B',\n",
       " '4C',\n",
       " '4D',\n",
       " '4E',\n",
       " '4F',\n",
       " '4H',\n",
       " '4I',\n",
       " '4J',\n",
       " '4K',\n",
       " '5B',\n",
       " '5E',\n",
       " '5I',\n",
       " '5J',\n",
       " '5K',\n",
       " '5L',\n",
       " '5M',\n",
       " '6',\n",
       " '6B',\n",
       " '6C',\n",
       " '6E',\n",
       " '7',\n",
       " '7A',\n",
       " '7B',\n",
       " '7C',\n",
       " '7D',\n",
       " '7E',\n",
       " '7F',\n",
       " '7G',\n",
       " '7H',\n",
       " '7I',\n",
       " '7R',\n",
       " '8',\n",
       " '8C',\n",
       " '8F',\n",
       " '8G',\n",
       " '8H',\n",
       " '8M',\n",
       " '9',\n",
       " '9B',\n",
       " '9C',\n",
       " '9D',\n",
       " '9E',\n",
       " '9F',\n",
       " '9G',\n",
       " '9R']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18b311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b175fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general311",
   "language": "python",
   "name": "general311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
